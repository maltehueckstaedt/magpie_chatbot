{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG mit Langchain\n",
    "\n",
    "## Einführung\n",
    "\n",
    "Im folgenden wird eine RAG für die Magpie gebaut. Ziel ist es, einen Chatbot zu genieren, der Fragen in natürlicher Sprache aufnimmt, diese in passende SQL-Abfragen umwandelt. Diese werden wiederum dem hinter dem Chatbot stehenden LMM als Kontext übermittelt, sodass dieser wiederum in natürlicher Sprache antworten kann. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Aktuelles Arbeitsverzeichnis ermitteln\n",
    "os.getcwd()\n",
    "os.chdir(\"c:/Users/Hueck/OneDrive/Dokumente/GitHub/magpie_langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden der Magpie\n",
    "\n",
    "Wir laden weiterhin die Magpie und stellen eine Verbindung zu ihr her:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(\"data/magpie.db\")\n",
    "cursor = conn.cursor()\n",
    "#conn.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration der Magpie\n",
    "\n",
    "Zu exploration wählen wir den Datensatz `datensatz_drittmittel_hochschule` und wandeln diesen in einen pandas-dataframe um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hueck\\AppData\\Local\\Temp\\ipykernel_26540\\2468430590.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)  #! conn ist die Verbindung zu deiner DuckDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       jahr      id                 Variable       Zeit  \\\n",
      "0      2006   30746     Drittmittel vom Bund 2006-01-01   \n",
      "1      2007   30747     Drittmittel vom Bund 2007-01-01   \n",
      "2      2008   30748     Drittmittel vom Bund 2008-01-01   \n",
      "3      2010   30750     Drittmittel vom Bund 2010-01-01   \n",
      "4      2011   30751     Drittmittel vom Bund 2011-01-01   \n",
      "...     ...     ...                      ...        ...   \n",
      "87855  2021  118392  Drittmittel von der DFG 2021-01-01   \n",
      "87856  2021  118406  Drittmittel von der DFG 2021-01-01   \n",
      "87857  2021  118418  Drittmittel von der DFG 2021-01-01   \n",
      "87858  2021  118475  Drittmittel von der DFG 2021-01-01   \n",
      "87859  2021  118595  Drittmittel von der DFG 2021-01-01   \n",
      "\n",
      "                                              Hochschule     Wert  \\\n",
      "0                                     Universität Kassel   3966.0   \n",
      "1                                     Universität Kassel   6274.0   \n",
      "2                                     Universität Kassel   5980.0   \n",
      "3                                     Universität Kassel  10226.0   \n",
      "4                                     Universität Kassel  12200.0   \n",
      "...                                                  ...      ...   \n",
      "87855     Eberhard Karls Universität Tübingen (Klinikum)  26448.0   \n",
      "87856           Pädagogische Hochschule Schwäbisch Gmünd     16.0   \n",
      "87857     Hochschule der Wirtschaft für Management gGmbH      0.0   \n",
      "87858              Akademie der Bildenden Künste München      0.0   \n",
      "87859  Friedrich-Schiller-Universität Jena (ohne Klin...  42604.0   \n",
      "\n",
      "            Einheit                       Quelle  \n",
      "0      in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "1      in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "2      in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "3      in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "4      in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "...             ...                          ...  \n",
      "87855  in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "87856  in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "87857  in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "87858  in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "87859  in Tsd. Euro  Destatis (Sonderauswertung)  \n",
      "\n",
      "[87860 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tabelle 'datensatz_fue_erhebung' in ein Pandas-DataFrame laden\n",
    "query = \"SELECT * FROM datensatz_drittmittel_hochschule;\"\n",
    "df = pd.read_sql(query, conn)  #! conn ist die Verbindung zu deiner DuckDB \n",
    "# DataFrame anzeigen\n",
    "print(df)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden von llama3.1 über Ollama\n",
    "\n",
    "In einem Schritt wird über Ollama das LLM `llama3.1` geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "import re\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b-instruct-q4_0\",\n",
    "    temperature=0,\n",
    "    server_url=\"http://127.0.0.1:11434\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird zunächst die `SQLDatabase`-Klasse aus dem Modul `langchain_community.utilities` importiert. Anschließend wird mit `SQLDatabase.from_uri(\"duckdb:///data/drittmittel_hs.db\")` eine Verbindung zur DuckDB-Datenbank namens `drittmittel_hs.db` im Verzeichnis `data` aufgebaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hueck\\miniconda3\\envs\\RAG_LLM\\lib\\site-packages\\duckdb_engine\\__init__.py:174: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"duckdb:///data/drittmittel_hs.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `get_sql_chain(llm, db, table_info, top_k=10)` erstellt eine SQL-Query-Kette, die basierend auf einer Benutzereingabe SQL-Abfragen generiert. Der Parameter `llm` steht für ein Sprachmodell (hier `llama3.1:8b-instruct-q4_0`), das zur Erstellung der SQL-Abfragen verwendet wird. Das Datenbankobjekt `db` liefert Informationen über die Datenbank, einschließlich Tabellen und deren Schema. `table_info` enthält detaillierte Informationen zu den Tabellen, wie Spalten und Datentypen. Der Parameter `top_k` gibt die maximale Anzahl der zurückzugebenden Zeilen an, wobei der Standardwert 10 ist. Im ersten Schritt wird ein `PromptTemplate` definiert, der Anweisungen für das Sprachmodell enthält, um valide SQL-Abfragen zu generieren. Anschließend wird mit diesem Template die SQL-Query-Kette erstellt, die von anderen Funktionen genutzt werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "\n",
    "def get_sql_chain(llm, db, table_info, top_k=10):\n",
    "\n",
    "    # * |||||||||||||||||||||||||||||||||||||||||||||\n",
    "    # * Comment: In einem ersten Schritt wir das Objekt\n",
    "    # * `template` erzeugt. Es leitet das LLM an, aus \n",
    "    # * der Anfrage des Nutzer ()\n",
    "    # * |||||||||||||||||||||||||||||||||||||||||||||\n",
    "    \n",
    "    template = f\"\"\"Given an input question, first create a syntactically\n",
    "    correct SQL query to run in {db.dialect}, then look at the results of the\n",
    "    query and return the answer to the input question. You can order the\n",
    "    results to return the most informative data in the database.\n",
    "    \n",
    "    Unless otherwise specified, do not return more than {{top_k}} rows.\n",
    "\n",
    "    Never query for all columns from a table. You must query only the\n",
    "    columns that are needed to answer the question. Wrap each column name\n",
    "    in double quotes (\") to denote them as delimited identifiers.\n",
    "\n",
    "    Pay attention to use only the column names present in the tables\n",
    "    below. Be careful to not query for columns that do not exist. Also, pay\n",
    "    attention to which column is in which table. Query only the columns you\n",
    "    need to answer the question.\n",
    "\n",
    "    Please carefully think before you answer.\n",
    "\n",
    "    Here is the schema for the database:\n",
    "    {{table_info}}\n",
    "\n",
    "    Return only the SQL query such that your response could be copied\n",
    "    verbatim into the SQL terminal.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    sql_chain = create_sql_query_chain(llm, db, prompt)\n",
    "\n",
    "    return sql_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duckdb'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion `natural_language_chain`\n",
    "\n",
    "Die Funktion `natural_language_chain` dient dazu, eine natürliche Sprachfrage eines Benutzers in eine SQL-Abfrage zu übersetzen, diese Abfrage auf einer Datenbank auszuführen und anschließend das Ergebnis in einer klar verständlichen Sprache zu präsentieren. Die Funktion funktioniert wie folgt:\n",
    "\n",
    "Zunächst wird mit `db.get_table_info()` die Struktur der Datenbank abgefragt, um Informationen über Tabellen, Spalten und Datentypen zu erhalten. Diese Daten sind essenziell, damit die SQL-Abfrage später korrekt formuliert werden kann und mit der Datenbankstruktur kompatibel ist.\n",
    "\n",
    "Anschließend wird eine sogenannte SQL-Abfrage-Kette (`sql_chain`) generiert. Dabei wird ein Large Language Model (LLM) verwendet, das die Benutzerfrage analysiert und auf Basis der Tabelleninformationen eine präzise SQL-Abfrage erstellt. Die Funktion `get_sql_chain` kümmert sich hierbei um die Übersetzung von natürlicher Sprache in eine SQL-Abfrage.\n",
    "\n",
    "Ein wichtiges Element der Funktion ist das definierte Template, das den Rahmen für die Antwort vorgibt. Dieses Template beschreibt den Kontext, dass der Chatbot „Sparklehorse“ heißt und für den „Stifterverband für die Deutsche Wissenschaft“ entwickelt wurde. Es legt fest, wie die SQL-Abfrage, die Benutzerfrage und das SQL-Ergebnis kombiniert werden, um eine passende Antwort zu generieren.\n",
    "\n",
    "Bevor die eigentliche Kette ausgeführt wird, wird eine Zwischenschritt-Kette (`intermediate_chain`) erstellt. Diese extrahiert zunächst nur die SQL-Abfrage aus der generierten SQL-Abfrage-Kette. Der resultierende SQL-String wird für Debugging-Zwecke ausgegeben, damit die generierte SQL-Abfrage überprüft werden kann.\n",
    "\n",
    "Die vollständige Verarbeitung erfolgt über eine kombinierte Kette, die mehrere Schritte umfasst:\n",
    "1. Die SQL-Abfrage wird ausgeführt, und das Ergebnis aus der Datenbank wird zurückgegeben.\n",
    "2. Dieses Ergebnis wird zusammen mit der ursprünglichen Benutzerfrage und der SQL-Abfrage in das definierte Template eingefügt.\n",
    "3. Das LLM nutzt das Template, um eine verständliche Antwort in natürlicher Sprache zu formulieren.\n",
    "\n",
    "Am Ende wird die fertige Antwort, die auf der ursprünglichen Frage, der SQL-Abfrage und dem Datenbankergebnis basiert, dem Benutzer präsentiert. Die Funktion gibt diese Antwort auch zurück, sodass sie in weiteren Prozessen verwendet werden kann.\n",
    "\n",
    "Zusammengefasst kombiniert die Funktion die Stärken eines LLM mit der Datenbankabfrage, um eine präzise, verständliche und kontextsensitive Antwort auf eine natürliche Sprachfrage zu liefern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_language_chain(question, llm, db):\n",
    "\n",
    "    # * |||||||||||||||||||||||||||||||||||||||||||||\n",
    "    # * Comment: Es wird mit db.get_table_info() in-\n",
    "    # * formation über die db (magpie) abgerufen.\n",
    "    # * |||||||||||||||||||||||||||||||||||||||||||||\n",
    "\n",
    "    table_info = db.get_table_info()\n",
    "    sql_chain = get_sql_chain(llm, db, table_info=table_info)\n",
    "\n",
    "    template = f\"\"\"\n",
    "        You are a chatbot named >>Sparklehorse<< created by the \n",
    "        >>Stifterverband für die Deutsche Wissenschaft<<. Based on the table schema given below, the SQL query and the SQL response, enter an answer\n",
    "        that corresponds to the language of the user's question. Think carefully and make sure that your answer is precise and easy to understand.\n",
    "\n",
    "        SQL Query: {{query}}\n",
    "        User question: {{question}}\n",
    "        SQL Response: {{response}}\n",
    "        \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    # Create the intermediate chain to extract SQL query\n",
    "    intermediate_chain = RunnablePassthrough.assign(query=sql_chain)\n",
    "\n",
    "    # Get the SQL query\n",
    "    intermediate_result = intermediate_chain.invoke({\"question\": question})\n",
    "    sql_query = intermediate_result[\"query\"]\n",
    "\n",
    "    # Debug: Print the SQL query\n",
    "    print(\"Generated SQL Query for Debugging:\")\n",
    "    print(sql_query)\n",
    "\n",
    "    # Continue with the full chain execution\n",
    "    chain = (\n",
    "        intermediate_chain.assign(\n",
    "            response=itemgetter(\"query\") | QuerySQLDataBaseTool(db=db)\n",
    "        )\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    response = chain.invoke({\"question\": question})\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query for Debugging:\n",
      "SELECT \"Wert\"\n",
      "FROM datensatz_drittmittel_hochschule\n",
      "WHERE \"Variable\" = 'Drittmittel von Gemeinden und Zweckverbänden'\n",
      "AND \"Hochschule\" = 'Universität Kassel'\n",
      "AND jahr = 2008;\n",
      "Die Drittmittel von Gemeinden und Zweckverbänden der Universität Kassel beliefen sich im Jahr 2008 auf 108.000 Euro.\n"
     ]
    }
   ],
   "source": [
    "_ = natural_language_chain('Wie hoch waren die \"Drittmittel von Gemeinden und Zweckverbänden\" der Universität Kassel im Jahr 2008?', llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = natural_language_chain('Was ist der Stifterverband?', llm, db)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
