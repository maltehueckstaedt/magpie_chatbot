{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparklehorse - Der SQL-Chatbot der Magpie\n",
    "\n",
    "## 1. Einleitung\n",
    "\n",
    "Hintergrund (Todo)\n",
    "\n",
    "Als Datenbank wird eine mview genutzt, die auf der Magpie basiert. Diese mview soll regelmäßig aktualisiert werden, um die neuesten Daten zu reflektieren. Der Chatbot ist so konzipiert, dass er SQL-Abfragen generieren kann, die auf den in der mview gespeicherten Daten basieren. \n",
    "\n",
    "## 2. Vorbereitung Sparklehorse\n",
    "\n",
    "### 2.1 Arbeitsverzeichnis\n",
    "\n",
    "In einem ersten Schritt definieren wir unser Arbeitsverzeichnis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:28:58.992809Z",
     "start_time": "2025-04-22T13:28:58.987369Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"c:/Users/mhu/Documents/gitHub/magpie_chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 API Key\n",
    "\n",
    "Wir laden unsere Umgebungsvariablen (inkl. OpenAI-API-Key) und initialisiere den Chatbot mit dem Modell \"gpt-4o\" von OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:29:02.082018Z",
     "start_time": "2025-04-22T13:29:01.593612Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Im folgenden stellen wir Verbindung zur Magpie her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhu\\AppData\\Local\\miniconda3\\envs\\chatbot_magpie\\lib\\site-packages\\duckdb_engine\\__init__.py:184: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit \n",
    "\n",
    "db = SQLDatabase.from_uri(\"duckdb:///data/view_magpie.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sparklehorse Tools\n",
    "\n",
    "Im LangChain-Framework sind Tools Funktionen oder Schnittstellen, die ein Agent (hier Sparklehorse) aufrufen kann, um bestimmte Aufgaben außerhalb des reinen Textverstehens zu erledigen. Sie erweitern die Fähigkeiten des Agenten flexibel. \n",
    "\n",
    "### 3.1 Standardisierte Langchain Tools\n",
    "\n",
    "Wir initialisieren ein standardisiertes Toolkit. Es stellt Tools bereit, um SQL-Queries über natürliche Sprache zu erzeugen und auszuführen. Wir lassen uns Namen und Funktion der standardisierten Tools anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: sql_db_query\n",
      "Description: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "----------------------------------------\n",
      "Tool Name: sql_db_schema\n",
      "Description: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
      "----------------------------------------\n",
      "Tool Name: sql_db_list_tables\n",
      "Description: Input is an empty string, output is a comma-separated list of tables in the database.\n",
      "----------------------------------------\n",
      "Tool Name: sql_db_query_checker\n",
      "Description: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(f\"Tool Name: {tool.name}\")\n",
    "    print(f\"Description: {tool.description}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standardtools aus`SQLDatabaseToolkit` können also die folgenden Standardfunktionen übernehmen: \n",
    "\n",
    "- `sql_db_query`  \n",
    "  Führt eine übergebene SQL-Abfrage aus. Gibt das Ergebnis oder eine Fehlermeldung zurück. Bei Fehlern wie „Unknown column“ sollte zuvor das Tabellenschema geprüft werden.\n",
    "\n",
    "- `sql_db_schema`  \n",
    "  Gibt das Schema (Spaltennamen und -typen) sowie Beispielzeilen für angegebene Tabellen zurück. Vorher sollte geprüft werden, ob die Tabellen existieren.\n",
    "\n",
    "- `sql_db_list_tables`  \n",
    "  Listet alle Tabellen in der verbundenen Datenbank auf.\n",
    "\n",
    "- `sql_db_query_checker`  \n",
    "  Prüft eine SQL-Abfrage auf syntaktische Korrektheit, bevor sie mit sql_db_query ausgeführt wird. Sollte immer vorher verwendet werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Maßgeschneiderte Langchain Tools\n",
    "\n",
    "#### 3.2.1 Tool Nr.1: `variable_beschr`\n",
    "\n",
    "Das Tool `variable_beschr` soll es ermöglichen, aus der eingegebenen Frage eines Nutzers die korrekte Variable aus der Magpie zu identifizieren. Dazu verwendet `variable_beschr` (1) den `rt_beschr_variable`-Retriever: `rt_beschr_variable` erlaubt die semantischen Suche über Werte aus der Variable `variable_beschr`: `rt_beschr_variable`  sammelt sämtliche unique Werte aus `beschr_variable` und wandelt diese mit OpenAIs Embeddings-Methode `text-embedding-3-large` in Embeddings um. Diese werden in einen Vektorstore gesichert. Der Vektorstore wird in einen Retriever umgewandelt, der bei einer Anfrage die `n=10` ähnlichsten Begriffe zurückgibt. Schließlich wird mit `create_retriever_tool` ein Tool erzeugt, das den Retriever kapselt. Dieses Tool wird von `variable_beschr` genutzt, um Benutzereingaben mit unsicherer Schreibweise oder unvollständigen Begriffen mit den tatsächlichen Werten der Variablen in der Magpie abzugleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Externe FuE-Aufwendungen\n",
      "FuE-Aufwendungen (vom Wirtschaftssektor finanziert)\n",
      "FuE-Aufwendungen (vom Staatssektor finanziert)\n",
      "Externe FuE für nicht verbundene Unternehmen (Inland)\n",
      "Externe FuE (Netto)\n",
      "Externe FuE für verbundene Unternehmen (Inland)\n",
      "Externe FuE für staatliche Forschungsinstitute (Inland)\n",
      "Interne FuE-Aufwendungen\n",
      "Externe FuE (Wirtschaft)\n",
      "Externe FuE für sonstige Institutionen und Unternehmen (Ausland)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def query_as_list(db, query):\n",
    "    res = db.run(query)\n",
    "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
    "    res = [string.strip() for string in res]\n",
    "    return list(set(res))\n",
    "\n",
    "\n",
    "beschr_variable = query_as_list(db, \"SELECT variable_beschr FROM view_daten_reichweite_menge\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_texts(beschr_variable)\n",
    "\n",
    "retriever_beschr_variable  = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "description = (\n",
    "    \"Verwenden, um Werte für Filterabfragen nachzuschlagen. Die Eingabe ist eine ungefähre Schreibweise \"\n",
    "    \"eines Eigennamens, die Ausgabe sind gültige Eigennamen. Verwende den Begriff, der der Eingabe am ähnlichsten ist.\"\n",
    ")\n",
    "\n",
    "rt_beschr_variable = create_retriever_tool(\n",
    "    retriever_beschr_variable,\n",
    "    name=\"rt_beschr_variable\",\n",
    "    description=description,\n",
    ")\n",
    "\n",
    "#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "# Comment: Test des Retriever-Tools\n",
    "#:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "def print_clean_result(result):\n",
    "    print(\"\\n\".join(result.split(\"\\n\\n\")))\n",
    "\n",
    "result = rt_beschr_variable.invoke(\"Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\")\n",
    "\n",
    "print_clean_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das eigentliche Tool `variable_beschr` geht wie folgt vor: Es nimmt eine Nutzerfrage entgegen und verwendet den `rt_beschr_variable`-Retriever, um mithilfe von Embeddings eine Liste relevanter Variablenbeschreibungen aus einer vektorisierten Dokumentensammlung zu finden. Falls keine passenden Kandidaten gefunden werden, gibt das Tool eine Fehlermeldung zurück. Andernfalls wird ein Prompt generiert, der das Sprachmodell auffordert, exakt eine Variable aus dieser Liste auszuwählen – jedoch nur, wenn diese wirklich präzise zur eingegebenen Frage passt. Das Modell gibt daraufhin den exakten Text der ausgewählten Variable zurück. Dieser wird anschließend in einer SQL-Abfrage verwendet, um zu überprüfen, ob die Variable in der Datenbank vorhanden ist. Wird sie gefunden, gibt das Tool sie zurück. Falls nicht, wird eine Rückmeldung generiert, die den Nutzer zur genaueren Spezifikation auffordert.\n",
    "\n",
    "Warum genügt nicht der einfache Retriever `rt_beschr_variable` für das Suchen der korrekten Variable? Im Rahmen des Testings hat sich gezeigt, dass die Korrekte Variable nicht umnbedingt jene ist, die die stärkste semantische Ähnlichkeit zur Nutzerfrage aufweist. Daher wird das Tool `variable_beschr` benötigt, um die Variable zu identifizieren, die auch inhatlich am besten zur Frage passt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "@tool\n",
    "def variable_beschr(user_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Nutzt ein LLM und Embeddings, um aus der Frage eine passende Variable zu bestimmen\n",
    "    und gibt dann die exakte Variable aus der Datenbank zurück.\n",
    "    \"\"\"\n",
    "    docs = retriever_beschr_variable.get_relevant_documents(user_question)\n",
    "    if not docs:\n",
    "        return \"Error: Keine passende Variable gefunden.\"\n",
    "\n",
    "    kandidaten = \"\\n\".join(f\"- {doc.page_content.strip()}\" for doc in docs)\n",
    "    print(kandidaten)\n",
    "\n",
    "    auswahl_prompt = PromptTemplate(\n",
    "        input_variables=[\"frage\", \"kandidaten\"],\n",
    "        template=\"\"\"\n",
    "    Wähle exakt **eine** der folgenden Variablen, die am besten zur Frage passt.\n",
    "    Wähle **nur dann** eine Variable aus, wenn sie **exakt** zur Frage passt.\n",
    "    Nutze **keine verwandten Begriffe**, Oberkategorien oder Synonyme.\n",
    "    Gib den Text **genau so** zurück, wie er bei den Kandidaten steht.\n",
    "\n",
    "    Frage: {frage}\n",
    "\n",
    "    Kandidaten:\n",
    "    {kandidaten}\n",
    "\n",
    "    Beste Variable:\n",
    "    \"\"\"\n",
    "    )\n",
    "    auswahl_chain = auswahl_prompt | llm\n",
    "    best_match = auswahl_chain.invoke({\n",
    "        \"frage\": user_question,\n",
    "        \"kandidaten\": kandidaten\n",
    "    }).content.strip()\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT variable_beschr \n",
    "        FROM view_daten_reichweite_menge \n",
    "        WHERE variable_beschr = '{best_match}' \n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "    result = db.run_no_throw(query)\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        return \"[USER_CLARIFICATION_NEEDED] Ich konnte keine passende Variable finden. Bitte geben Sie die gewünschte Variable genauer an.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir testen nun das Tool Nr.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhu\\AppData\\Local\\Temp\\ipykernel_18332\\3452618517.py:11: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever_beschr_variable.get_relevant_documents(user_question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Externe FuE-Aufwendungen\n",
      "- FuE-Aufwendungen (vom Wirtschaftssektor finanziert)\n",
      "- FuE-Aufwendungen (vom Staatssektor finanziert)\n",
      "- Externe FuE für nicht verbundene Unternehmen (Inland)\n",
      "- Externe FuE (Netto)\n",
      "- Externe FuE für verbundene Unternehmen (Inland)\n",
      "- Externe FuE für staatliche Forschungsinstitute (Inland)\n",
      "- Interne FuE-Aufwendungen\n",
      "- Externe FuE (Wirtschaft)\n",
      "- Externe FuE für sonstige Institutionen und Unternehmen (Ausland)\n",
      "[('Externe FuE (Wirtschaft)',)]\n"
     ]
    }
   ],
   "source": [
    "test_input = \"Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\"\n",
    "output = variable_beschr(test_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Tool Nr.2: `rt_reichweite_variable`\n",
    "\n",
    "  Wir bauen einen ähnlichen Retriever nun auch für die Variablen `reichweite_beschr_list`. Das Tool `get_reichweite_beschr_list` bestimmt aus der Nutzerfrage die passende Reichweite zu einer Variable. Dazu nutzt es zuerst `variable_beschr`, das aus der Frage die exakte Variable ermittelt (siehe oben). Anschließend fragt es mit dieser Variable die Datenbank nach möglichen Reichweiten ab. Diese Reichweiten werden dann mit einem Vektor-Speicher und Text-Embeddings semantisch mit der Nutzerfrage verglichen, um die fünf relevantesten Kandidaten zu finden. Mithilfe eines Few-Shot-Prompts, das dem Modell anhand von Beispielen zeigt, wann `Deutschland` trotz semantisch ähnlicher anderer Reichweiten die richtige Wahl ist, wählt das Sprachmodell die beste Reichweite aus. Wird keine passende Reichweite gefunden oder ist die Auswahl ungültig, fordert das Tool eine genauere Eingabe vom Nutzer an. Abschließend wird die gewählte Reichweite noch einmal über die Datenbank validiert und als Ergebnis zurückgegeben. So kombiniert das Tool Datenbankabfragen, semantische Suche und gezielte Steuerung des Modells, um die passende Reichweite kontextsensitiv zu ermitteln.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "reichweiten_beispiele = [\n",
    "    {\"frage\": \"Wie viele Absolventen für Berufliche Schulen gab es?\", \"variable_beschr\": \"Anzahl der Absolventen für Berufliche Schulen\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war die Studierquote bildungsferner Schichten?\", \"variable_beschr\": \"Studierquote bildungsferne Schichten\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele dauerhaft eingestellte Lehrkräfte (inkl. Seiteneinsteigern, ohne Referendare) gab es?\", \"variable_beschr\": \"Anzahl dauerhaft eingestellte Lehrkräfte (inkl. Seiteneinsteigern, ohne Referendare)\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war der Handlungsfeldindex: Lehrer Bildung?\", \"variable_beschr\": \"Handlungsfeldindex: Lehrer Bildung\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele Universitätsschulverbünde gab es?\", \"variable_beschr\": \"Anzahl Universitätsschulverbünde\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war der Anteil berufsbegleitender Master?\", \"variable_beschr\": \"Anteil berufsbegleitender Master\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele Studienabsolventen T gab es?\", \"variable_beschr\": \"Studienabsolventen T\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch waren die internen FuE-Aufwendungen?\", \"variable_beschr\": \"Interne FuE-Aufwendungen\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war der Anteil der männlichen Grundschullehramtsstudierenden?\", \"variable_beschr\": \"Anteil der männlichen Grundschullehramtsstudierende\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele Studienabsolventen im Weiterbildungsstudium gab es?\", \"variable_beschr\": \"Studienabsolventen im Weiterbildungsstudium\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch waren die Drittmittel vom Bund 2021 in Deutschland?\", \"variable_beschr\": \"Drittmittel vom Bund\", \"reichweite_beschr_list\": \"Deutschland\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"frage\", \"variable_beschr\", \"reichweite_beschr_list\"],\n",
    "    template=\"Frage: {frage}\\nVariable: {variable_beschr}\\n→ Reichweite: {reichweite_beschr_list}\"\n",
    ")\n",
    "\n",
    "reichweite_prompt = FewShotPromptTemplate(\n",
    "    examples=reichweiten_beispiele,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Wähle aus den möglichen Reichweiten die beste. Nutze 'Deutschland', wenn keine Region, Organisation o. Ä. genannt wird.\",\n",
    "    suffix=\"Frage: {frage}\\nVariable: {variable_beschr}\\nKandidaten:\\n{kandidaten}\\n→ Reichweite:\",\n",
    "    input_variables=[\"frage\", \"variable_beschr\", \"kandidaten\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_reichweite_beschr_list(user_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Ermittelt eine passende Reichweite (z. B. Region, Organisation, etc.), basierend auf der\n",
    "    zur Frage gehörigen Variable und den verfügbaren Einträgen in der Datenbank.\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] Eingabe-Frage:\", user_question)\n",
    "\n",
    "    raw_variable = variable_beschr.run(user_question)\n",
    "    print(\"[DEBUG] raw_variable:\", raw_variable)\n",
    "\n",
    "    match = re.search(r\"'([^']+)'\", str(raw_variable))\n",
    "    if not match:\n",
    "        print(\"[DEBUG] Abbruch: Keine gültige Variable extrahiert\")\n",
    "        return \"Fehler: Konnte keine gültige Variable bestimmen.\"\n",
    "\n",
    "    variable = match.group(1)\n",
    "    print(\"[DEBUG] bereinigte variable:\", variable)\n",
    "\n",
    "    if \"Error\" in variable:\n",
    "        return \"Fehler: Konnte keine gültige Variable bestimmen.\"\n",
    "\n",
    "    escaped_variable = variable.replace(\"'\", \"''\")\n",
    "    print(\"[DEBUG] escaped_variable:\", escaped_variable)\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT reichweite_beschr_list \n",
    "        FROM view_daten_reichweite_menge \n",
    "        WHERE variable_beschr = '{escaped_variable}'\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] SQL-Abfrage gültige_reichweiten:\", query)\n",
    "    gültige_reichweiten = query_as_list(db, query)\n",
    "    print(\"[DEBUG] gültige_reichweiten:\", gültige_reichweiten)\n",
    "\n",
    "    if not gültige_reichweiten:\n",
    "        return \"[USER_CLARIFICATION_NEEDED] Ich konnte keine passende Reichweite ermitteln. Bitte präzisieren Sie, welche Region oder Organisation gemeint ist.\"\n",
    "\n",
    "\n",
    "    vector_store = InMemoryVectorStore(OpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
    "    _ = vector_store.add_texts(gültige_reichweiten)\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    top_matches = retriever.get_relevant_documents(user_question)\n",
    "    reichweiten_kandidaten = [doc.page_content for doc in top_matches]\n",
    "    print(\"[DEBUG] Top 5 Reichweiten-Kandidaten:\", reichweiten_kandidaten)\n",
    "\n",
    "    kandidaten_text = \"\\n\".join(reichweiten_kandidaten)\n",
    "\n",
    "    llm_chain = reichweite_prompt | llm\n",
    "    best_match = llm_chain.invoke({\n",
    "        \"frage\": user_question,\n",
    "        \"variable_beschr\": variable,\n",
    "        \"kandidaten\": kandidaten_text\n",
    "    }).content.strip()\n",
    "\n",
    "    print(\"[DEBUG] LLM-best_match:\", best_match)\n",
    "\n",
    "    # Validierung: nur erlaubte Rückgabe\n",
    "    if best_match not in gültige_reichweiten:\n",
    "        print(f\"[DEBUG] LLM-Match ungültig ('{best_match}'), Rückfrage erforderlich\")\n",
    "        return \"[USER_CLARIFICATION_NEEDED] Ich konnte keine passende Reichweite ermitteln. Bitte konkretisieren Sie Ihre Anfrage.\"\n",
    "        \n",
    "    query = f\"\"\"\n",
    "        SELECT reichweite_beschr_list \n",
    "        FROM view_daten_reichweite_menge \n",
    "        WHERE reichweite_beschr_list = '{best_match}' \n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] SQL-Abfrage finale Auswahl:\", query)\n",
    "    result = db.run_no_throw(query)\n",
    "    print(\"[DEBUG] Ergebnis:\", result)\n",
    "\n",
    "    return result if result else \"Error: Keine passende Reichweite gefunden.\"\n",
    "\n",
    "tools.extend([variable_beschr, get_reichweite_beschr_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir testen nun das Tool Nr.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Eingabe-Frage: Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\n",
      "- Externe FuE-Aufwendungen\n",
      "- FuE-Aufwendungen (vom Wirtschaftssektor finanziert)\n",
      "- FuE-Aufwendungen (vom Staatssektor finanziert)\n",
      "- Externe FuE für nicht verbundene Unternehmen (Inland)\n",
      "- Externe FuE (Netto)\n",
      "- Externe FuE für verbundene Unternehmen (Inland)\n",
      "- Externe FuE für staatliche Forschungsinstitute (Inland)\n",
      "- Interne FuE-Aufwendungen\n",
      "- Externe FuE (Wirtschaft)\n",
      "- Externe FuE für sonstige Institutionen und Unternehmen (Ausland)\n",
      "[DEBUG] raw_variable: [('Externe FuE-Aufwendungen',)]\n",
      "[DEBUG] bereinigte variable: Externe FuE-Aufwendungen\n",
      "[DEBUG] escaped_variable: Externe FuE-Aufwendungen\n",
      "[DEBUG] SQL-Abfrage gültige_reichweiten: \n",
      "        SELECT DISTINCT reichweite_beschr_list \n",
      "        FROM view_daten_reichweite_menge \n",
      "        WHERE variable_beschr = 'Externe FuE-Aufwendungen'\n",
      "    \n",
      "[DEBUG] gültige_reichweiten: ['Wirtschaftssektor | Deutschland | Maschinenbau', 'Wirtschaftssektor | Deutschland | Hochwertige Technik', 'Wirtschaftssektor | Deutschland | Architektur-, Ing.büros, techn., phys., chem. Untersuchung', 'Wirtschaftssektor | Deutschland | Information und Kommunikation', 'Wirtschaftssektor | Deutschland | 50 bis 99 Beschäftigte', 'Wirtschaftssektor | Deutschland | Landwirtschaft, Forstwirtschaft und Fischerei', 'Wirtschaftssektor | Deutschland | Institutionen für Gemeinschaftsforschung', 'Wirtschaftssektor | Deutschland', 'Wirtschaftssektor | Deutschland | H.v. chemischen Erzeugnissen', 'Wirtschaftssektor | Deutschland | 250 bis 499 Beschäftigte', 'Wirtschaftssektor | Deutschland | Programmierungstätigkeiten', 'Wirtschaftssektor | Deutschland | Wissenschaftliche Forschung und Entwicklung', 'Wirtschaftssektor | Deutschland | Energie- und Wasservers., Abwasser- und Abfallentsorgung', 'Wirtschaftssektor | Deutschland | Spitzentechnologie', 'Wirtschaftssektor | Deutschland | H.v. Gummi- und Kunststoffwaren', 'Wirtschaftssektor | Deutschland | Verarbeitendes Gewerbe', 'Wirtschaftssektor | Deutschland | 1000 bis 1999 Beschäftigte', 'Wirtschaftssektor | Deutschland | Forschungsintensive Wirtschaftszweige', 'Wirtschaftssektor | Deutschland | Sonst. H. v. Waren, Rep.u.Inst.von Maschinen u. Ausrüstungen', 'Wirtschaftssektor | Deutschland | H.v. elektrischen Ausrüstungen', 'Wirtschaftssektor | Deutschland | Restliche Abschnitte (nicht forschungsintensiv)', 'Wirtschaftssektor | Deutschland | 10000 und mehr Beschäftigte', 'Wirtschaftssektor | Deutschland | H.v. Holzwaren, Papier, Pappe und Druckerzeugnissen', 'Wirtschaftssektor | Deutschland | H.v. Kraftwagen und Kraftwagenteilen', 'Wirtschaftssektor | Deutschland | Metallerzeugung und -bearbeitung', 'Wirtschaftssektor | Deutschland | weniger als 20 Beschäftigte', 'Wirtschaftssektor | Deutschland | Baugewerbe/Bau', 'Wirtschaftssektor | Deutschland | 2000 bis 4999 Beschäftigte', 'Wirtschaftssektor | Deutschland | weniger als 250 Beschäftigte', 'Wirtschaftssektor | Deutschland | 5000 und mehr Beschäftigte', 'Wirtschaftssektor | Deutschland | 100 bis 249 Beschäftigte', 'Wirtschaftssektor | Deutschland | Finanz- und Versicherungsdienstleistungen', 'Wirtschaftssektor | Deutschland | 500 bis 999 Beschäftigte', 'Wirtschaftssektor | Deutschland | H.v. Metallerzeugnissen', 'Wirtschaftssektor | Deutschland | H.v. pharmazeutischen Erzeugnissen', 'Wirtschaftssektor | Deutschland | H.v. Glas u. Glaswaren, Keramik, Verarb. v. Steinen u. Erden', 'Wirtschaftssektor | Deutschland | H.v. DV-Geräten, elektronischen u. opt. Erzeugnissen', 'Wirtschaftssektor | Deutschland | Bergbau und Gewinnung von Steinen und Erden', 'Wirtschaftssektor | Deutschland | 1000 und mehr Beschäftigte', 'Wirtschaftssektor | Deutschland | Sonstiger Fahrzeugbau', 'Wirtschaftssektor | Deutschland | 5000 bis 9999 Beschäftigte', 'Wirtschaftssektor | Deutschland | 50 bis 249 Beschäftigte', 'Wirtschaftssektor | Deutschland | H.v. Nahrungs- u. Futtermitteln, Getränken u.Tabakerzeugn.', 'Wirtschaftssektor | Deutschland | Restliche Abschnitte', 'Wirtschaftssektor | Deutschland | 20 bis 49 Beschäftigte', 'Wirtschaftssektor | Deutschland | H.v. Textilien, Bekleidung, Leder, Lederwaren und Schuhen', 'Wirtschaftssektor | Deutschland | Freiberufliche, wissenschaftl. u. techn. Dienstleistungen', 'Wirtschaftssektor | Deutschland | 500 bis 1999 Beschäftigte', 'Wirtschaftssektor | Deutschland | Luft- und Raumfahrzeugbau', 'Wirtschaftssektor | Deutschland | Kokerei und Mineralölverarbeitung', 'Wirtschaftssektor | Deutschland | 500 und mehr Beschäftigte', 'Wirtschaftssektor | Deutschland | weniger als 100 Beschäftigte']\n",
      "[DEBUG] Top 5 Reichweiten-Kandidaten: ['Wirtschaftssektor | Deutschland | Forschungsintensive Wirtschaftszweige', 'Wirtschaftssektor | Deutschland | Wissenschaftliche Forschung und Entwicklung', 'Wirtschaftssektor | Deutschland | Restliche Abschnitte (nicht forschungsintensiv)', 'Wirtschaftssektor | Deutschland | Spitzentechnologie', 'Wirtschaftssektor | Deutschland | 500 und mehr Beschäftigte']\n",
      "[DEBUG] LLM-best_match: Wirtschaftssektor | Deutschland | Forschungsintensive Wirtschaftszweige\n",
      "[DEBUG] SQL-Abfrage finale Auswahl: \n",
      "        SELECT reichweite_beschr_list \n",
      "        FROM view_daten_reichweite_menge \n",
      "        WHERE reichweite_beschr_list = 'Wirtschaftssektor | Deutschland | Forschungsintensive Wirtschaftszweige' \n",
      "        LIMIT 1;\n",
      "    \n",
      "[DEBUG] Ergebnis: [('Wirtschaftssektor | Deutschland | Forschungsintensive Wirtschaftszweige',)]\n",
      "[('Wirtschaftssektor | Deutschland | Forschungsintensive Wirtschaftszweige',)]\n"
     ]
    }
   ],
   "source": [
    "test_input = \"Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\"\n",
    "output = get_reichweite_beschr_list(test_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt_template = hub.pull(\"langchain-ai/sql-agent-system-prompt\")\n",
    "\n",
    "assert len(prompt_template.messages) == 1, \"Die Anzahl der Nachrichten im Template ist nicht 1!\"\n",
    "# Bearbeite die bestehende Nachricht, indem du Text hinzufügst\n",
    "prompt_template.messages[0].prompt.template += (\n",
    "    \"\\nYou are Sparklehorse, a chatbot for the Stifterverband organization. \"\n",
    "    \"Your primary task is to answer questions related to the Magpie database.\"\n",
    ")\n",
    "\n",
    "prompt_template.messages[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = prompt_template.format(\n",
    "    dialect=db.dialect, \n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Systemnachricht mit extra Anweisungen\n",
    "suffix = (\n",
    "    \"Bevor du eine SQL-Abfrage generierst, beachte bitte folgende Regeln strikt:\\n\"\n",
    "    \"1. Nutze das Tool `variable_beschr`, um die korrekte Variable aus der Nutzerfrage zu bestimmen. Verwende ausschließlich den exakten Rückgabewert dieses Tools für `variable_beschr` in der SQL-Abfrage.\\n\"\n",
    "    \"2. Nutze das Tool `get_reichweite_beschr_list`, um die passende Reichweite zu ermitteln. Verwende ausschließlich den Rückgabewert dieses Tools für `reichweite_beschr_list` in der SQL-Abfrage.\\n\"\n",
    "    \"3. Verwende **niemals** andere Felder wie `tag_list` oder `LIKE`-Abfragen. Nutze **immer exakte Vergleiche** mit `=`.\\n\"\n",
    "    \"4. Verwende ausschließlich die Tabelle `view_daten_reichweite_menge` für alle Abfragen.\\n\"\n",
    "    \"5. Falls ein Jahr in der Frage genannt wird, filtere mit `date_part('year', zeit_start) = <Jahr>`.\\n\"\n",
    "    \"6. Berücksichtige die Spalte `wert_einheit`, z. B. 'in Tsd. Euro', 'Anzahl', 'Prozent', 'VZÄ', 'Mitarbeiter'.\\n\"\n",
    "    \"7. Gib immer die finale SQL-Abfrage vollständig aus und erkläre sie. Rate niemals IDs oder Werte.\\n\"\n",
    "    \"8. Falls keine passende Variable oder Reichweite gefunden wurde, rate nicht irgendwelche Werte. \\n\"\n",
    "    \"9. Stelle sicher, dass Antworttext und SQL-Abfrage immer auf den gleichen `variable_beschr`- und `reichweite_beschr_list`-Werten basieren, um Konsistenz zu gewährleisten.\\n\"\n",
    "    \"10. Verwende in deiner Antwort exakt die Begriffe, die du in der SQL-Abfrage benutzt hast. Nutze insbesondere den Wert aus `reichweite_beschr_list` vollständig im Antwortsatz. Beispiel: Wenn `reichweite_beschr_list = 'Wirtschaftssektor | Deutschland'`, schreibe: 'im Wirtschaftssektor in Deutschland'.\\n\"\n",
    "    \"11. Beantworte ausschließlich Fragen zur Magpie-Datenbank. Wenn eine Frage nichts mit den Variablen, Reichweiten oder Daten aus der Magpie-Datenbank zu tun hat, antworte mit: 'Ich kann nur Fragen zur Magpie-Datenbank beantworten.'\"\n",
    "\n",
    ")\n",
    "\n",
    " \n",
    "system = f\"{system_message}\\n\\n{suffix}\"\n",
    "\n",
    "# Neuen ReAct-Agent erstellen mit den vollständigen Tools\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_agent_with_check(question: str):\n",
    "    stream = agent_executor.stream({\"messages\": [HumanMessage(content=question)]}, stream_mode=\"values\")\n",
    "    for step in stream:\n",
    "        msg = step[\"messages\"][-1]\n",
    "        if \"[USER_CLARIFICATION_NEEDED]\" in msg.content:\n",
    "            rückfrage = msg.content.replace(\"[USER_CLARIFICATION_NEEDED]\", \"\").strip()\n",
    "            print(f\"⚠️ Rückfrage: {rückfrage}\")\n",
    "            break\n",
    "        else:\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testanfrage an den Agenten\n",
    "question = \"Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\"\n",
    "\n",
    "stream_agent_with_check(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "df = pd.read_excel(\"data/test_quest_mixed_nr_5.xlsx\").sample(n=20, random_state=1)\n",
    " \n",
    "for question in df[\"Frage\"].dropna():\n",
    "    result = agent_executor.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    messages = result[\"messages\"]\n",
    "    antwort = messages[-1].content\n",
    "    print(f\"\\nFrage: {question}\\nAntwort: {antwort}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def ask_with_memory(user_input):\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    response = agent_executor.invoke({\"messages\": chat_history})\n",
    "    reply = response[\"messages\"][-1]\n",
    "    chat_history.append(reply)\n",
    "    return reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_with_memory(\"Wie hoch waren die FuE-Ausgaben 2022 in Deutschland?\"))\n",
    "print(ask_with_memory(\"Und im Jahr davor?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_with_memory(\"Wer ist Norbert Elias?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_magpie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
