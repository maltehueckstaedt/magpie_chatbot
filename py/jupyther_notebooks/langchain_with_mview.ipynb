{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparklehorse - Der SQL-Chatbot der Magpie\n",
    "\n",
    "## 1. Vorbereitung\n",
    "\n",
    "In einem ersten Schritt definieren wir unser Arbeitsverzeichnis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:28:58.992809Z",
     "start_time": "2025-04-22T13:28:58.987369Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"c:/Users/mhu/Documents/gitHub/magpie_chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir laden unsere Umgebungsvariablen (inkl. OpenAI-API-Key) und initialisiere den Chatbot mit dem Modell \"gpt-4o\" von OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-22T13:29:02.082018Z",
     "start_time": "2025-04-22T13:29:01.593612Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Im folgenden stellen wir Verbindung zur Magpie her."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhu\\AppData\\Local\\miniconda3\\envs\\chatbot_magpie\\lib\\site-packages\\duckdb_engine\\__init__.py:184: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit \n",
    "\n",
    "db = SQLDatabase.from_uri(\"duckdb:///data/view_magpie.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tools\n",
    "\n",
    "### 2.1 Standardisierte Langchain Tools\n",
    "\n",
    "Wir initialisieren ein standardisiertes Toolkit. Es stellt Funktionen bereit, um SQL-Queries über natürliche Sprache zu erzeugen und auszuführen. Wir lassen uns Namen und Funktion der standardisierten Tools anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: sql_db_query\n",
      "Description: Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\n",
      "----------------------------------------\n",
      "Tool Name: sql_db_schema\n",
      "Description: Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3\n",
      "----------------------------------------\n",
      "Tool Name: sql_db_list_tables\n",
      "Description: Input is an empty string, output is a comma-separated list of tables in the database.\n",
      "----------------------------------------\n",
      "Tool Name: sql_db_query_checker\n",
      "Description: Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for tool in tools:\n",
    "    print(f\"Tool Name: {tool.name}\")\n",
    "    print(f\"Description: {tool.description}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standardtools aus`SQLDatabaseToolkit` können also die folgenden Standardfunktionen übernehmen: \n",
    "\n",
    "- `sql_db_query`  \n",
    "  Führt eine übergebene SQL-Abfrage aus. Gibt das Ergebnis oder eine Fehlermeldung zurück. Bei Fehlern wie „Unknown column“ sollte zuvor das Tabellenschema geprüft werden.\n",
    "\n",
    "- `sql_db_schema`  \n",
    "  Gibt das Schema (Spaltennamen und -typen) sowie Beispielzeilen für angegebene Tabellen zurück. Vorher sollte geprüft werden, ob die Tabellen existieren.\n",
    "\n",
    "- `sql_db_list_tables`  \n",
    "  Listet alle Tabellen in der verbundenen Datenbank auf.\n",
    "\n",
    "- `sql_db_query_checker`  \n",
    "  Prüft eine SQL-Abfrage auf syntaktische Korrektheit, bevor sie mit sql_db_query ausgeführt wird. Sollte immer vorher verwendet werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Maßgeschneiderte Langchain Tools\n",
    "\n",
    "#### Retriever `rt_beschr_variable`\n",
    "\n",
    "`rt_beschr_variable` erlaubt die semantischen Suche über Werte aus einer Datenbankspalte. \n",
    "\n",
    "1. Wir sammeln sämtliche Unique Werte aus `beschr_variable` und wandeln diese mit OpenAIs Embeddings-Methdode `text-embedding-3-large` in Embeddings um. Die werden in einen Vektorstore gesichert.\n",
    "2. Der Vektorstore wird in einen Retriever umgewandelt, der bei einer Anfrage die `n=10` ähnlichsten Begriffe zurückgibt.\n",
    "3. Schließlich wird mit `create_retriever_tool` ein Tool erzeugt, das den Retriever kapselt. Dieses Tool kann von Sparklehorse genutzt werden, um Benutzereingaben mit unsicherer Schreibweise oder unvollständigen Begriffen mit den tatsächlichen Werten in der Datenbank abzugleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def query_as_list(db, query):\n",
    "    res = db.run(query)\n",
    "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
    "    res = [string.strip() for string in res]\n",
    "    return list(set(res))\n",
    "\n",
    "\n",
    "beschr_variable = query_as_list(db, \"SELECT variable_beschr FROM view_daten_reichweite_menge\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_texts(beschr_variable)\n",
    "\n",
    "retriever_beschr_variable  = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "description = (\n",
    "    \"Verwenden, um Werte für Filterabfragen nachzuschlagen. Die Eingabe ist eine ungefähre Schreibweise \"\n",
    "    \"eines Eigennamens, die Ausgabe sind gültige Eigennamen. Verwende den Begriff, der der Eingabe am ähnlichsten ist.\"\n",
    ")\n",
    "\n",
    "rt_beschr_variable = create_retriever_tool(\n",
    "    retriever_beschr_variable,\n",
    "    name=\"rt_beschr_variable\",\n",
    "    description=description,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir testen nun den Retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Studienabsolventen ohne Abitur\n",
      "Anzahl der Studienanfänger ohne Abitur\n",
      "Anteil der Studienanfänger ohne Abitur\n",
      "Anteil der Studienabsolventen ohne Abitur\n",
      "Studienanfänger 1. FS Lehramt nach angestr. Prüfungen Bachelor + Staatsexamen im 1. Hochschulsemester\n",
      "Studienabsolventen Bildungsausländer\n",
      "Studienabsolventen im Weiterbildungsstudium\n",
      "Studienanfänger 1. FS Lehramt nach angestr. Prüfungen Bachelor + Staatsexamen (ges. Studienjahr)\n",
      "Studierende\n",
      "Studienabsolventen Bildungsinländer\n"
     ]
    }
   ],
   "source": [
    "def print_clean_result(result):\n",
    "    print(\"\\n\".join(result.split(\"\\n\\n\")))\n",
    "\n",
    "result = rt_beschr_variable.invoke(\"Studienanfänger ohne Abitur\")\n",
    "\n",
    "print_clean_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever `rt_reichweite_variable`\n",
    "\n",
    "Wir bauen einen ähnlichen Retriever nun auch für die Variablen `reichweite_beschr_list`. Allerdings begrenzen wir die uniquen Reichweiten auf jene einer Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "def invoke_agent_with_check(question: str):\n",
    "    result = agent_executor.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    messages = result[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    if isinstance(last_message, AIMessage) and \"[USER_CLARIFICATION_NEEDED]\" in last_message.content:\n",
    "        rückfrage = last_message.content.replace(\"[USER_CLARIFICATION_NEEDED]\", \"\").strip()\n",
    "        return f\"⚠️ Rückfrage: {rückfrage}\"\n",
    "    else:\n",
    "        return last_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "reichweiten_beispiele = [\n",
    "    {\"frage\": \"Wie viele Absolventen für Berufliche Schulen gab es?\", \"variable_beschr\": \"Anzahl der Absolventen für Berufliche Schulen\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war die Studierquote bildungsferner Schichten?\", \"variable_beschr\": \"Studierquote bildungsferne Schichten\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele dauerhaft eingestellte Lehrkräfte (inkl. Seiteneinsteigern, ohne Referendare) gab es?\", \"variable_beschr\": \"Anzahl dauerhaft eingestellte Lehrkräfte (inkl. Seiteneinsteigern, ohne Referendare)\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war der Handlungsfeldindex: Lehrer Bildung?\", \"variable_beschr\": \"Handlungsfeldindex: Lehrer Bildung\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele Universitätsschulverbünde gab es?\", \"variable_beschr\": \"Anzahl Universitätsschulverbünde\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war der Anteil berufsbegleitender Master?\", \"variable_beschr\": \"Anteil berufsbegleitender Master\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele Studienabsolventen T gab es?\", \"variable_beschr\": \"Studienabsolventen T\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch waren die internen FuE-Aufwendungen?\", \"variable_beschr\": \"Interne FuE-Aufwendungen\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch war der Anteil der männlichen Grundschullehramtsstudierenden?\", \"variable_beschr\": \"Anteil der männlichen Grundschullehramtsstudierende\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie viele Studienabsolventen im Weiterbildungsstudium gab es?\", \"variable_beschr\": \"Studienabsolventen im Weiterbildungsstudium\", \"reichweite_beschr_list\": \"Deutschland\"},\n",
    "    {\"frage\": \"Wie hoch waren die Drittmittel vom Bund 2021 in Deutschland?\", \"variable_beschr\": \"Drittmittel vom Bund\", \"reichweite_beschr_list\": \"Deutschland\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"frage\", \"variable_beschr\", \"reichweite_beschr_list\"],\n",
    "    template=\"Frage: {frage}\\nVariable: {variable_beschr}\\n→ Reichweite: {reichweite_beschr_list}\"\n",
    ")\n",
    "\n",
    "reichweite_prompt = FewShotPromptTemplate(\n",
    "    examples=reichweiten_beispiele,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Wähle aus den möglichen Reichweiten die beste. Nutze 'Deutschland', wenn keine Region, Organisation o. Ä. genannt wird.\",\n",
    "    suffix=\"Frage: {frage}\\nVariable: {variable_beschr}\\nKandidaten:\\n{kandidaten}\\n→ Reichweite:\",\n",
    "    input_variables=[\"frage\", \"variable_beschr\", \"kandidaten\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "@tool\n",
    "def variable_beschr(user_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Nutzt ein LLM und Embeddings, um aus der Frage eine passende Variable zu bestimmen\n",
    "    und gibt dann die exakte Variable aus der Datenbank zurück.\n",
    "    \"\"\"\n",
    "    docs = retriever_beschr_variable.get_relevant_documents(user_question)\n",
    "    if not docs:\n",
    "        return \"Error: Keine passende Variable gefunden.\"\n",
    "\n",
    "    kandidaten = \"\\n\".join(f\"- {doc.page_content.strip()}\" for doc in docs)\n",
    "    print(kandidaten)\n",
    "\n",
    "    auswahl_prompt = PromptTemplate(\n",
    "        input_variables=[\"frage\", \"kandidaten\"],\n",
    "        template=\"\"\"\n",
    "    Wähle exakt **eine** der folgenden Variablen, die am besten zur Frage passt.\n",
    "    Wähle **nur dann** eine Variable aus, wenn sie **exakt** zur Frage passt.\n",
    "    Nutze **keine verwandten Begriffe**, Oberkategorien oder Synonyme.\n",
    "    Gib den Text **genau so** zurück, wie er bei den Kandidaten steht.\n",
    "\n",
    "    Frage: {frage}\n",
    "\n",
    "    Kandidaten:\n",
    "    {kandidaten}\n",
    "\n",
    "    Beste Variable:\n",
    "    \"\"\"\n",
    "    )\n",
    "    auswahl_chain = auswahl_prompt | llm\n",
    "    best_match = auswahl_chain.invoke({\n",
    "        \"frage\": user_question,\n",
    "        \"kandidaten\": kandidaten\n",
    "    }).content.strip()\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT variable_beschr \n",
    "        FROM view_daten_reichweite_menge \n",
    "        WHERE variable_beschr = '{best_match}' \n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "    result = db.run_no_throw(query)\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        return \"[USER_CLARIFICATION_NEEDED] Ich konnte keine passende Variable finden. Bitte geben Sie die gewünschte Variable genauer an.\"\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "@tool\n",
    "def get_reichweite_beschr_list(user_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Ermittelt eine passende Reichweite (z. B. Region, Organisation, etc.), basierend auf der\n",
    "    zur Frage gehörigen Variable und den verfügbaren Einträgen in der Datenbank.\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] Eingabe-Frage:\", user_question)\n",
    "\n",
    "    raw_variable = variable_beschr.run(user_question)\n",
    "    print(\"[DEBUG] raw_variable:\", raw_variable)\n",
    "\n",
    "    match = re.search(r\"'([^']+)'\", str(raw_variable))\n",
    "    if not match:\n",
    "        print(\"[DEBUG] Abbruch: Keine gültige Variable extrahiert\")\n",
    "        return \"Fehler: Konnte keine gültige Variable bestimmen.\"\n",
    "\n",
    "    variable = match.group(1)\n",
    "    print(\"[DEBUG] bereinigte variable:\", variable)\n",
    "\n",
    "    if \"Error\" in variable:\n",
    "        return \"Fehler: Konnte keine gültige Variable bestimmen.\"\n",
    "\n",
    "    escaped_variable = variable.replace(\"'\", \"''\")\n",
    "    print(\"[DEBUG] escaped_variable:\", escaped_variable)\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT reichweite_beschr_list \n",
    "        FROM view_daten_reichweite_menge \n",
    "        WHERE variable_beschr = '{escaped_variable}'\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] SQL-Abfrage gültige_reichweiten:\", query)\n",
    "    gültige_reichweiten = query_as_list(db, query)\n",
    "    print(\"[DEBUG] gültige_reichweiten:\", gültige_reichweiten)\n",
    "\n",
    "    if not gültige_reichweiten:\n",
    "        return \"[USER_CLARIFICATION_NEEDED] Ich konnte keine passende Reichweite ermitteln. Bitte präzisieren Sie, welche Region oder Organisation gemeint ist.\"\n",
    "\n",
    "\n",
    "    vector_store = InMemoryVectorStore(OpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
    "    _ = vector_store.add_texts(gültige_reichweiten)\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    top_matches = retriever.get_relevant_documents(user_question)\n",
    "    reichweiten_kandidaten = [doc.page_content for doc in top_matches]\n",
    "    print(\"[DEBUG] Top 5 Reichweiten-Kandidaten:\", reichweiten_kandidaten)\n",
    "\n",
    "    kandidaten_text = \"\\n\".join(reichweiten_kandidaten)\n",
    "\n",
    "    llm_chain = reichweite_prompt | llm\n",
    "    best_match = llm_chain.invoke({\n",
    "        \"frage\": user_question,\n",
    "        \"variable_beschr\": variable,\n",
    "        \"kandidaten\": kandidaten_text\n",
    "    }).content.strip()\n",
    "\n",
    "    print(\"[DEBUG] LLM-best_match:\", best_match)\n",
    "\n",
    "    # Validierung: nur erlaubte Rückgabe\n",
    "    if best_match not in gültige_reichweiten:\n",
    "        print(f\"[DEBUG] LLM-Match ungültig ('{best_match}'), Rückfrage erforderlich\")\n",
    "        return \"[USER_CLARIFICATION_NEEDED] Ich konnte keine passende Reichweite ermitteln. Bitte konkretisieren Sie Ihre Anfrage.\"\n",
    "        \n",
    "    query = f\"\"\"\n",
    "        SELECT reichweite_beschr_list \n",
    "        FROM view_daten_reichweite_menge \n",
    "        WHERE reichweite_beschr_list = '{best_match}' \n",
    "        LIMIT 1;\n",
    "    \"\"\"\n",
    "    print(\"[DEBUG] SQL-Abfrage finale Auswahl:\", query)\n",
    "    result = db.run_no_throw(query)\n",
    "    print(\"[DEBUG] Ergebnis:\", result)\n",
    "\n",
    "    return result if result else \"Error: Keine passende Reichweite gefunden.\"\n",
    "\n",
    "\n",
    "\n",
    "tools.extend([variable_beschr, get_reichweite_beschr_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im Sektor wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\"\n",
    "output = variable_beschr(test_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = \"Wie hoch waren die drittmittel vom bund, im Jahr 2021, in Deutschland?\"\n",
    "output = get_reichweite_beschr_list(test_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt_template = hub.pull(\"langchain-ai/sql-agent-system-prompt\")\n",
    "\n",
    "assert len(prompt_template.messages) == 1, \"Die Anzahl der Nachrichten im Template ist nicht 1!\"\n",
    "# Bearbeite die bestehende Nachricht, indem du Text hinzufügst\n",
    "prompt_template.messages[0].prompt.template += (\n",
    "    \"\\nYou are Sparklehorse, a chatbot for the Stifterverband organization. \"\n",
    "    \"Your primary task is to answer questions related to the Magpie database.\"\n",
    ")\n",
    "\n",
    "prompt_template.messages[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = prompt_template.format(\n",
    "    dialect=db.dialect, \n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Systemnachricht mit extra Anweisungen\n",
    "suffix = (\n",
    "    \"Bevor du eine SQL-Abfrage generierst, beachte bitte folgende Regeln strikt:\\n\"\n",
    "    \"1. Nutze das Tool `variable_beschr`, um die korrekte Variable aus der Nutzerfrage zu bestimmen. Verwende ausschließlich den exakten Rückgabewert dieses Tools für `variable_beschr` in der SQL-Abfrage.\\n\"\n",
    "    \"2. Nutze das Tool `get_reichweite_beschr_list`, um die passende Reichweite zu ermitteln. Verwende ausschließlich den Rückgabewert dieses Tools für `reichweite_beschr_list` in der SQL-Abfrage.\\n\"\n",
    "    \"3. Verwende **niemals** andere Felder wie `tag_list` oder `LIKE`-Abfragen. Nutze **immer exakte Vergleiche** mit `=`.\\n\"\n",
    "    \"4. Verwende ausschließlich die Tabelle `view_daten_reichweite_menge` für alle Abfragen.\\n\"\n",
    "    \"5. Falls ein Jahr in der Frage genannt wird, filtere mit `date_part('year', zeit_start) = <Jahr>`.\\n\"\n",
    "    \"6. Berücksichtige die Spalte `wert_einheit`, z. B. 'in Tsd. Euro', 'Anzahl', 'Prozent', 'VZÄ', 'Mitarbeiter'.\\n\"\n",
    "    \"7. Gib immer die finale SQL-Abfrage vollständig aus und erkläre sie. Rate niemals IDs oder Werte.\\n\"\n",
    "    \"8. Falls keine passende Variable oder Reichweite gefunden wurde, rate nicht irgendwelche Werte. \\n\"\n",
    "    \"9. Stelle sicher, dass Antworttext und SQL-Abfrage immer auf den gleichen `variable_beschr`- und `reichweite_beschr_list`-Werten basieren, um Konsistenz zu gewährleisten.\\n\"\n",
    "    \"10. Verwende in deiner Antwort exakt die Begriffe, die du in der SQL-Abfrage benutzt hast. Nutze insbesondere den Wert aus `reichweite_beschr_list` vollständig im Antwortsatz. Beispiel: Wenn `reichweite_beschr_list = 'Wirtschaftssektor | Deutschland'`, schreibe: 'im Wirtschaftssektor in Deutschland'.\\n\"\n",
    "    \"11. Beantworte ausschließlich Fragen zur Magpie-Datenbank. Wenn eine Frage nichts mit den Variablen, Reichweiten oder Daten aus der Magpie-Datenbank zu tun hat, antworte mit: 'Ich kann nur Fragen zur Magpie-Datenbank beantworten.'\"\n",
    "\n",
    ")\n",
    "\n",
    " \n",
    "system = f\"{system_message}\\n\\n{suffix}\"\n",
    "\n",
    "# Neuen ReAct-Agent erstellen mit den vollständigen Tools\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_agent_with_check(question: str):\n",
    "    stream = agent_executor.stream({\"messages\": [HumanMessage(content=question)]}, stream_mode=\"values\")\n",
    "    for step in stream:\n",
    "        msg = step[\"messages\"][-1]\n",
    "        if \"[USER_CLARIFICATION_NEEDED]\" in msg.content:\n",
    "            rückfrage = msg.content.replace(\"[USER_CLARIFICATION_NEEDED]\", \"\").strip()\n",
    "            print(f\"⚠️ Rückfrage: {rückfrage}\")\n",
    "            break\n",
    "        else:\n",
    "            msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testanfrage an den Agenten\n",
    "question = \"Wie hoch waren die externe fue-aufwendungen, im Jahr 2020, in Deutschland, im Sektor wirtschaftssektor, bei forschungsintensive wirtschaftszweige Forschung?\"\n",
    "\n",
    "stream_agent_with_check(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "df = pd.read_excel(\"data/test_quest_mixed_nr_5.xlsx\").sample(n=20, random_state=1)\n",
    " \n",
    "for question in df[\"Frage\"].dropna():\n",
    "    result = agent_executor.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    messages = result[\"messages\"]\n",
    "    antwort = messages[-1].content\n",
    "    print(f\"\\nFrage: {question}\\nAntwort: {antwort}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def ask_with_memory(user_input):\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    response = agent_executor.invoke({\"messages\": chat_history})\n",
    "    reply = response[\"messages\"][-1]\n",
    "    chat_history.append(reply)\n",
    "    return reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_with_memory(\"Wie hoch waren die FuE-Ausgaben 2022 in Deutschland?\"))\n",
    "print(ask_with_memory(\"Und im Jahr davor?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_with_memory(\"Wer ist Norbert Elias?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_magpie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
